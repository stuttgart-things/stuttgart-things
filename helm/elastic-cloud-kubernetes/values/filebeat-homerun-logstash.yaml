---
apiVersion: beat.k8s.elastic.co/v1beta1
kind: Beat
metadata:
  name: filebeat
spec:
  type: filebeat
  version: 8.14.2
  elasticsearchRef:
    name: elasticsearch-cluster
    namespace: elastic-system
  kibanaRef:
    name: kibana
    namespace: elastic-system
  config:
    output.elasticsearch:
      enabled: false
    output.logstash:
      hosts: ["logstash-ls-beats.elastic-system.svc.cluster.local:5044"]
    filebeat.autodiscover.providers:
      - node: ${NODE_NAME}
        type: kubernetes
        hints.default_config.enabled: "false"
        templates:
          - condition.equals.kubernetes.namespace: homerun
            config:
              - paths: ["/var/log/containers/*${data.kubernetes.container.id}.log"]
                type: container
          # - condition.equals.kubernetes.namespace: awx
          #   config:
          #     - paths: ["/var/log/containers/*${data.kubernetes.container.id}.log"]
          #       type: container
          # - condition.equals.kubernetes.labels.log-label: "true"
          #   config:
          #     - paths: ["/var/log/containers/*${data.kubernetes.container.id}.log"]
          #       type: container
    processors:
      - add_cloud_metadata: {}
      - add_host_metadata: {}
  daemonSet:
    podTemplate:
      spec:
        serviceAccountName: filebeat
        automountServiceAccountToken: true
        terminationGracePeriodSeconds: 30
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true # Allows to provide richer host metadata
        containers:
        - name: filebeat
          securityContext:
            runAsUser: 0
          volumeMounts:
          - name: varlogcontainers
            mountPath: /var/log/containers
          - name: varlogpods
            mountPath: /var/log/pods
          - name: varlibdockercontainers
            mountPath: /var/lib/docker/containers
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
        volumes:
        - name: varlogcontainers
          hostPath:
            path: /var/log/containers
        - name: varlogpods
          hostPath:
            path: /var/log/pods
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
---
apiVersion: logstash.k8s.elastic.co/v1alpha1
kind: Logstash
metadata:
  name: logstash
  namespace: elastic-system
spec:
  count: 1
  version: 8.14.2
  elasticsearchRefs:
    - name: elasticsearch-cluster
      clusterName: elasticsearch-cluster
  pipelines:
    # - pipeline.id: awx
    #   config.string: |
    #     input {
    #       beats {
    #         port => 5044
    #       }
    #     }

    #     filter {
    #       grok {
    #         match => { "message" => "%{HTTPD_COMMONLOG}"}
    #       }
    #       geoip {
    #         source => "[source][address]"
    #         target => "[source]"
    #       }
    #     }

    #     output {
    #       elasticsearch {
    #         hosts => [ "${ELASTICSEARCH_CLUSTER_ES_HOSTS}" ]
    #         user => "${ELASTICSEARCH_CLUSTER_ES_USER}"
    #         password => "${ELASTICSEARCH_CLUSTER_ES_PASSWORD}"
    #         ssl_certificate_authorities => "${ELASTICSEARCH_CLUSTER_ES_SSL_CERTIFICATE_AUTHORITY}"
    #       }
    #       stdout {
    #         codec => rubydebug
    #       }
    #     }
    - pipeline.id: homerun
      config.string: |
        input {
          beats {
            port => 5044
          }
        }

        filter {
          # GENERIC-PITCHER (GITHUB-ACTIONS)
          grok {
            match => { "message" => " \{%{GREEDYDATA:username} %{DATE_US:date} %{TIME:time} %{GREEDYDATA:event_title} REPOSITORY: %{DATA:github_repository} WORKFLOW: %{DATA:github_workflow} ARTIFACT: %{DATA:artifact} BUILD-PARAMETER: %{DATA:build_parameter} RUNNER_NAME: %{DATA:github_runner} WORKFLOW-IMAGE: %{DATA:workflow_image} ENV: %{DATA:env} %{GREEDYDATA:event_tags} %{WORD:event_severity}\}"}
          }

          mutate {
            split => { "event_tags" => "," }
          }

          # GITLAB-PITCHER
          grok {
            match => { "message" => "MESSAGE: \{%{USERNAME:username} %{TIMESTAMP_ISO8601:timestamp} (?<event_type>%{WORD} %{WORD}) (?<repository>%{WORD}-%{WORD}-%{WORD}) %{WORD:system} %{WORD:severity}"}
          }

        }

        output {
          elasticsearch {
            hosts => [ "${ELASTICSEARCH_CLUSTER_ES_HOSTS}" ]
            user => "${ELASTICSEARCH_CLUSTER_ES_USER}"
            password => "${ELASTICSEARCH_CLUSTER_ES_PASSWORD}"
            ssl_certificate_authorities => "${ELASTICSEARCH_CLUSTER_ES_SSL_CERTIFICATE_AUTHORITY}"
          }

          stdout {
            codec => rubydebug
          }
        }
  services:
    - name: beats
      service:
        spec:
          type: ClusterIP
          ports:
            - port: 5044
              name: "filebeat"
              protocol: TCP
              targetPort: 5044
  volumeClaimTemplates:
    - metadata:
        name: logstash-data # Do not change this name unless you set up a volume mount for the data path.
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 2Gi
        storageClassName: nfs-csi
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: filebeat
rules:
- apiGroups: [""] # "" indicates the core API group
  resources:
  - namespaces
  - pods
  - nodes
  verbs:
  - get
  - watch
  - list
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: filebeat
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: filebeat
subjects:
- kind: ServiceAccount
  name: filebeat
  namespace: default
roleRef:
  kind: ClusterRole
  name: filebeat
  apiGroup: rbac.authorization.k8s.io



# 2024-08-08 04:27:24,173 INFO      [e5d86920e1f442deb179db7145f9319a] awx.analytics.job_lifecycle job-32 finalize run {"type": "job", "task_id": 32, "state": "finalize_run", "work_unit_id": "wn4G455B", "task_name": "render-upload-template"}
# %{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:loglevel}\s+\[%{DATA:request_id}\] %{DATA:module} %{DATA:job} %{DATA:state} %{DATA:name} \{"type": "%{WORD:type}", "task_id": %{NUMBER:task_id}, "state": "%{WORD:state}", "work_unit_id": "%{WORD:work_unit_id}", "task_name": "%{DATA:task_name}"\}



#%{LOGLEVEL:loglevel}\s+\[%{TIMESTAMP_ISO8601:timestamp}\] MESSAGE: \{%{USERNAME:username} %{TIMESTAMP_ISO8601:event_timestamp} %{ISO8601_TIMEZONE:timezone1} %{ISO8601_TIMEZONE:timezone2} %{WORD:event_type} %{WORD:project} %{WORD:source} %{WORD:log_level}\}
#INFO   [2024-08-08 05:30:37] MESSAGE: {machineShop 08-08-2024 05:30:37 image was not build w/ kaniko on github workflows no kaniko ERROR}